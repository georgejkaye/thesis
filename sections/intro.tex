\chapter{Introduction}

Today's society has become dependent on the humble digital circuit, which works
tirelessly inside our computers, homes, vehicles and many more.
These days, digital circuits are so common, so fundamental, that one may doubt
that there are \emph{any} gaps in our theoretical understanding of them.

But this depends on the perspective one chooses to take.
While the \emph{design} of increasingly more and more efficient circuits is a
well-trodden area, it is relatively self-contained.
We wish to reframe our view of digital circuits in such a way that techniques
that have been successfully applied in other fields, such as that of programming
languages, can be applied here also.

So we can see where the parallels lie between digital circuits and other areas,
we need a foundational, mathematically rigorous theory for the former.
Unfortunately, such a theory has thus far eluded us.

\section{Synchronous sequential circuits}

Of course, to define such a mathematical theory we must be precise about what
we mean.
The term \emph{circuit} (or \emph{network}) is sometimes used as a blanket term
for a system constructed by connecting wires between primitive components.
Even when restricting to \emph{electronic} circuits there are different flavours
to consider.
One might consider \emph{analog} circuits constructed from components such as
resistors, capacitors and transistors.
Reasoning with analog circuits requires manipulating equations relating
quantities such as voltage, current and resistance.

A \emph{digital} circuit working over a finite number of \emph{discrete}
values is quite different.
Here there is much stricter notion of causality linking input and output; the
input signals change and these propagate across the circuit, producing outputs
and updating state.
While every digital circuit could just be viewed as an analog circuit, the
discrete style of reasoning makes it far easier to design and reuse them.

We are concerned with the subclass of digital circuits known as
\emph{synchronous sequential circuits}.
In a \emph{sequential} circuit, the output at a given time can depend on any of
the inputs received since the circuit was switched on; succinctly, it is a
circuit with \emph{memory}.
Most sequential circuits can be divided into two parts:
\emph{combinational logic} for performing logical functions, and
\emph{state registers} for storing data.
While purely combinational circuits do exist, most useful circuits need
at least some memory.

How exactly these state registers change over time leads to an additional way
to classify sequential circuits.
A \emph{synchronous} circuit is one in which the state only changes in time with
some global clock signal.
On the other side of the coin, in \emph{asynchronous} circuits the state changes
as soon as the inputs do.
Such circuits are useful when speed is of the essence, but are harder to design
because of race conditions between circuit components: if one gate is slightly
faster then the circuit could temporarily assume an unexpected state and produce
the incorrect output.
For this reason, most practical circuits are restricted to the synchronous
flavour.

\section{Compositionality and category theory}


The first thing to pin down here is, of course, what does it mean for a theory
to be \emph{fully} compositional?
It is a term often thrown around without much thought to its precise meaning,
not least by the author.
Here, we take full compositionality to mean that we can compose circuits
without fear that we will somehow create something degenerate and leave our
well-behaved setting.
We should not have to perform any sort of semantic check or `peek inside' a
circuit to find out if composition is permitted; we should be able to treat
everything as a black box.

Compositionality is an appealing paradigm to follow because, rather than dealing
with complicated and unwieldy circuits, we can split them up into simpler
components.
These components can themselves be split up into simpler components and so on
until we reach some sort of atomic components that can be divided no further.
This means that if one defines the behaviour of these atomic components and
how they interact with composition, it is possible to quickly establish the
behaviour of some larger circuit \emph{inductively} by piecing things together.

Composition is not even restricted to the mathematical realm; it is generally
considered good practice to write programs in terms of small, easily reusable
pieces that can be pieced together by composing functions, which is why
functional programming paradigms are starting to creep into even the most
imperative of languages.

While it is perfectly reasonable to work with this abstract, surface-level
notion of compositionality, it is important to establish a rigorous mathematical
foundation to work out exactly what it means to compose and the properties that
arise from it; to do this, we turn to the field of
\emph{category theory}~\cite{maclane1978categories}.
As one might expect, category theory is the study of \emph{categories} which
contain \emph{objects} and \emph{morphisms} (`arrows') between them.
The only enforced properties are that these morphisms can be composed in an
associative manner and that every object has a special \emph{identity} morphism
that `does nothing'.
It turns out that these simple concepts pave the way to a dizzying array of
theorems that can be used to generalise many areas of computer science,
mathematics, and beyond.

Perhaps the most successful use of category theory for compositional processes
in recent times is for modelling
\emph{quantum protocols}~\cite{abramsky2004categorical}.
This line of work resulted in the
\emph{ZX calculus}~\cite{coecke2008interacting}, in which quantum
circuits are depicted by connecting so-called `spiders' together to create a
network.
This is a key example of \emph{string diagrams}~\cite{joyal1991geometry},
a graphical notation for morphisms in \emph{symmetric monoidal categories}.
While string diagrams do not add any more computational power to
standard one-dimensional reasoning, they are
immensely beneficial because the categorical axioms of associativity and
unitality are `absorbed' by the notation: two morphisms are equal if and only if
their string diagrams are isomorphic~\cite{kelly1980coherence,kissinger2014abstract}.
This makes proofs far less bureaucratic, meaning that the mathematician need
only focus on the non-trivial steps without having to constantly rearrange the
bracketing of a term.
As a useful aside, they also make the work more approachable and easier to
explain to non-mathematicians.
With string diagrams, it is possible to give talks about category theory without
even mentioning categories at all; there have even been books written with this
philosophy~\cite{coecke2018picturing}.

\section{Compositionality and sequential circuits}

One might argue that composition is already widespread in sequential circuit
design, and indeed it is: circuits are constructed by connecting lots of very
common primitive components together to make something more complex.
But this is done informally, as the behaviour of a circuit is usually tested
by \emph{simulating} it and seeing what happens.
We can simulate the subcomponents, but what does this mean for their composite?
Without a guarantee of full compositionality, we have no reason to
believe that connecting two well-behaved circuits together will result in
another well-behaved circuit: for example, there is always the threat of
creating a dreaded \emph{non-delay-guarded feedback loop}.

Some approaches try to nullify this by considering only some `safe' subset of
circuits which will always be well-behaved~\cite{christensen2021wire}, or by
introducing some sort of `type system' on wires so that components may only be
connected if their timings match up~\cite{nigam2023modular}.
While these are useful perspectives, they still shy away from true full
compositionality.
Our goals are simple: we wish to be able to compose \emph{any} two circuits
together without our reasoning falling apart.
The result of the composition may not be a useful circuit, but we will still
be able to see that this is the case.

Of course, we cannot claim that we are the first to bring mathematics to
sequential circuits.
\emph{Mealy machines}~\cite{mealy1955method}, the \emph{de facto} structure for
specifying the behaviour of sequential circuits, are ancient and it is well
known how they should be composed~\cite{ginzburg2014algebraic}.
In more recent times Mealy machines have been given a categorical treatment as
certain kinds of \emph{coalgebra}~\cite{rutten2006algebraic,bonsangue2008coalgebraic}.
However, Mealy machines abstract away from the \emph{components} of the circuit;
we are keen to preserve the link between structure and behaviour.

While not explicitly categorical, the idea of representing circuits as
mathematical expressions built up from primitive components was studied in the
80s by Mike Gordon, who worked on
\emph{denotational semantics for sequential machines}~\cite{gordon1980denotational}
and used this idea to present
\emph{a model of register transfer systems}~\cite{gordon1982model}.
Gordon subsequently noted that \emph{higher order logic} would make a good fit
for a hardware description language~\cite{gordon1985why}, and this has become
a ubiquitous concept in formal verification of hardware~\cite{gupta1992formal}.

It was at the turn of the millennium that the ball really got rolling when it
came to developing a \emph{categorical} theory of digital circuits.
In the early noughties, Yves Lafont presented an
\emph{algebraic theory of boolean circuits}~\cite{lafont2003algebraic}, which
already bears a great resemblance to the work presented in this thesis; circuits
are presented as morphisms in a symmetric monoidal category freely generated
over a set of primitive logic gates.

As the name might suggest, Lafont's work only considered circuits that
implemented \emph{Boolean functions}; these circuits did not have any notion of
delay or feedback.
It was not until 2016 that these circuits were given the categorical treatment
by Ghica and Jung~\cite{ghica2016categorical}, who were later joined
by Lopez when considering how to use this for a graph-rewriting based
operational semantics~\cite{ghica2017diagrammatic}.

While this thesis would not have come about without this foundational work, it
was presented in a different manner: the categories of circuits were quotiented
by some `natural laws' without consulting any sort of `baseline' mathematical
model.
Such laws could of course be tested experimentally, but to truly say we have a
`sound and complete` theory we need a formal model to compare any new model
against.

\section{Contributions}

This contributions of this thesis are split into two parts,
\emph{Semantics of Digital Circuits}, and
\emph{Graph Rewriting for Digital Circuits}.
These sections respectively correspond to two papers:
\emph{%
    A Fully Compositional Theory of Sequential Digital Circuits:
    Denotational, Operational and Algebraic Semantics%
}~\cite{ghica2024fully}, and \emph{%
    Rewriting Modulo Traced Monoidal Structure%
}~\cite{ghica2023rewriting}, which was published in
\emph{Formal Structures for Computation and Deduction (FSCD) 2023}.

\subsection{Semantics of Digital Circuits}

In the previous work, semantics of digital circuits was defined in a sometimes
confusing manner, intermingling equations on circuits with other quotients.
In the first part of this thesis we set about fixing this: we first define the
categorical syntax of sequential digital circuits and follow this up with three
sound and complete semantic frameworks: denotational, operational, and
algebraic.
Each of these frameworks has their own benefits and intended uses; together they
make a part of a comprehensive examination of semantics of digital circuits.
The framework is sufficiently general to encompass circuits constructed from
all manner of components ranging from the level of transistors to the level of
logic gates and beyond to higher abstraction, but to provide some intuition we
include an extended case study into circuits constructed from
\emph{Belnap logic gates}~\cite{belnap1977useful}, an extension of traditional
Boolean logic containing the usual \(\andgate\), \(\orgate\) and \(\notgate\)
gates.

\subsubsection{Denotational semantics}

While the previous circuits work discussed assigning semantics to circuits
of circuits in terms of streams, soundness and completeness of this model was
not considered.
It was not even deemed important enough to appear in the conference version of
the paper, only being examined in detail in the arXiv
preprint~\cite{ghica2017diagrammatica}.
Here we present a denotational semantics for sequential circuits as
\emph{stream functions} with certain properties using a traced PROP morphism
mapping syntax to semantics.
This denotational semantics is sound and complete in that every syntactic
circuit can be expressed as one of these stream functions, and every such stream
function can be mapped to a syntactic circuit which has the original stream
function as its behaviour.

Along the way, we also define a traced PROP of Mealy machines lifted to work on
lattices as a `bridge' between circuits and stream functions.
As well as being essential for showing the soundness and completeness of the
denotational semantics, having this category of Mealy machines is nice to have
in its own right, as it shows how existing circuit
methodologies~\cite{kohavi2009switching} are compatible with our rigorous
mathematic framework.

\subsubsection{Operational semantics}

The previous work on circuits was primarily motivated by creating an operational
semantics for digital circuits, bringing techniques from software to the realm
of hardware.
While such a system was presented in~\cite{ghica2017diagrammatic}, this only
worked on \emph{closed} circuits with no \emph{non-delay-guarded feedback}.
One of the main contributions of this section is a novel reduction rule for
eliminating non-delay-guarded feedback inspired by the Kleene fixpoint theorem,
which, combined with a generalisation of the previous reduction procedure to
work on open circuits, means that any circuit applied to some inputs can be
reduced in order to determine its outputs and next state.

As a result of this, we also present a formal notion of
\emph{observational equivalence} on sequential circuits, and show that it is the
correct one using the well-known universal property that it is the largest
adequate congruence relation~\cite{gordon1998operational}.

\subsubsection{Algebraic semantics}

One of the confusing points of the original work on circuits was the category
of circuits was quotiented by certain equations that `felt right'.
In the end these equations were not enough to show the desired results,
so additional quotients of `extensional equivalence' were used to add in the
remaining equalities.

In this thesis our equational theory is guided by the stream semantics,
building up to a sound and complete algebraic semantics for circuits without
having to add any arbitrary quotients.
We try to stick to standard equations on algebraic structures and small `local'
equations detailing the interactions on individual generators, but the nature of
digital circuits means that some larger circuits including \emph{context} are
necessary to include.
The main result is showing the equations suffice to bring any circuit to a
pseudo-normal form.

\subsection{Graph Rewriting for Digital Circuits}

While this work marks the first time the semantics of sequential digital
circuits have been given a rigorous mathematical treatment, it is not really
feasible to apply the techniques to anything more than toy circuits by hand;
trying to apply the techniques to actual, practical, circuits would quickly lead
to someone having a very bad time.
Instead it is desirable to have a computer deal with all the hard work
for us and reason \emph{automatically}.
To do this, we need to represent circuits \emph{combinatorially} as graphs.

Representing the categorical syntax of digital circuits in this way was
considered in~\cite{ghica2017diagrammatic} using
Kissinger's \emph{framed point graphs}~\cite{kissinger2012pictures}.
These had several drawbacks, such as the need to reason modulo
\emph{wire homeomorphism} and the fact that framed point graphs were not fully
adhesive.
In the second part of the thesis, we extend more recent work on
\emph{hypergraph string diagram rewriting}~\cite{bonchi2022string,bonchi2022stringa,bonchi2022stringb}
so we can apply it to sequential digital circuits; to be precise, we adapt it
for settings with a \emph{traced comonoid} structure.
Using graph rewriting, we can express the operational and algebraic semantics
in a language that is easy for computers can understand and reason with, opening
up the possibility for automatic reasoning about complex, actually useful,
digital sequential circuits.
