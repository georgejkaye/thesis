\chapter{Introduction}

Today's society has become dependent on digital
circuits~\cite{katz2005contemporary}, which run our computers, homes, vehicles
and much more.
These days, digital circuits are so common that one may doubt that there are
\emph{any} gaps in our theoretical understanding of them.

But while the \emph{design} of increasingly more efficient circuits is a
well-trodden area, it is relatively self-contained.
We wish to reframe our view of digital circuits in such a way that we can
support the existing techniques and procedures with alternatives successfully
applied in other fields, such as that of programming languages.
To see where the parallels lie between digital circuits and other areas,
we need a foundational, mathematically rigorous theory.
Although there has been previous work on such a
theory~\cite{lafont2003algebraic,ghica2017diagrammatic,ghica2018structural}, it
is the goal of this thesis to bring this project to its ultimate conclusion:
a \emph{fully compositional theory of synchronous sequential circuits}.
The first point of order is to unpack exactly what this means.

\section{Synchronous sequential circuits}

The term `\emph{circuit}' (or `\emph{network}') is often used for any system
constructed by connecting wires between primitive components.
While the components themselves may differ, two common constructs are the
ability to \emph{fork} wires or \emph{join} them together, traditionally drawn
using black dots as shown below.

\begin{center}
    \iltikzfig{circuits/forkjoin}
\end{center}

Even when restricting to \emph{electronic} circuits there are different flavours
to consider.
One variety is that of \emph{analog} circuits constructed from components such
as resistors, capacitors and inductors, such as in the following circuit
diagram.

\begin{center}
    \scalebox{0.5}{
        \begin{circuitikz}
            \draw (0,0) to[inductor] (2.5,0);
            \draw (2.5,0) to[short, *-] (4,0);
            \draw (4,0) to[resistor] (4,-2);
            \draw (2.5,0) to[capacitor] (2.5,-2);
            \draw (2.5,-2) to[short, *-] (4,-2);
            \draw (-2,-2) to[american voltage source] (2.5,-2);
            \draw (-2,0) to [voltmeter] (0,0);
            \draw (-2,-2) to (-2,0);
        \end{circuitikz}
    }
\end{center}

Reasoning with analog circuits requires manipulating equations relating
quantities such as voltage, current and resistance; in a parallel line of work
to our own, analog circuits have already been given a compositional mathematical
treatment~\cite{boisseau2022string}.

We are concerned with \emph{digital} circuits that operate over a finite
number of \emph{discrete} values.
Here there is a much stricter notion of causality linking input and output; the
input signals change and these propagate across the circuit, producing outputs
and updating state.
Digital circuits are constructed by connecting \emph{logic gates} together with
wires,
to the inputs of other logic gates,together with
wires, as illustrated in the below example.

\begin{center}
    \iltikzfig{circuits/examples/sr-latch/real-circuit-no-text}
\end{center}

A key point to note is that when designing a digital circuit, one may create
\emph{cycles}: paths from a component to itself.

At a low level a digital circuit is still constructed using analog circuit
component, but the higher-level \emph{abstraction} to digital components and
discrete signals makes it far easier to design and reuse them.

Digital circuits can further be divided into classes based on their components.
A \emph{combinational} circuit is a circuit that just contains logical
operations for computing functions.
Such circuits have no memory; the outputs at one tick of the clock only depend
on the inputs received at that moment.
A far more useful class of circuits is that of \emph{sequential} circuits, which
have have \emph{delay} and \emph{feedback} in addition to logic gates.
Most sequential circuits can be divided into two parts:
the \emph{combinational logic} for performing logical functions, an the
\emph{state registers} for storing data.

A typical digital circuit operates by using the combinational logic to perform
some function on the inputs and the current state, and use the results of this
computation to produce output signals and update the state with new data.
When circuits are used in practice, it is usually desired for them to run as
fast as possible: the time between providing the inputs and updating the
output and state should be minimised.

With this in mind, there are two different ways one can design a sequential
circuit.
A \emph{synchronous} circuit is one in which the state only changes in time with
some global clock signal, whereas in \emph{asynchronous} circuits the state
changes as soon as the inputs do.
The latter type of circuits are useful when speed is of the essence, but are
harder to design because small differences in how quickly components process
inputs can lead to the circuit assuming an unexpected state.
For this reason, most practical circuits are restricted to the synchronous
kind, and so this is where we are focusing our mathematical theory.

\section{Compositionality and category theory}

From a high level, a (synchronous sequential) circuit is a component with some
input and output wires that we can connect to other components to create a
bigger circuit.
This is known as being able to \emph{compose} circuits based on their
interfaces; we can compose circuits \emph{horizontally} (if the outputs of the
first match with the inputs of the second), \emph{vertically}, or even by
connecting an output wire to an input wire, creating a \emph{feedback loop}.

\begin{center}
    \iltikzfig{strings/category/composition}
    \qquad
    \iltikzfig{strings/monoidal/tensor}
    \qquad
    \iltikzfig{strings/traced/trace-rhs}
\end{center}

Our goal is to define a \emph{fully compositional} theory of synchronous
sequential circuits.
Here, we take full compositionality to mean that we can compose circuits solely
on the basis of their interfaces: we should not have to perform any sort of
semantic check or `peek inside' a circuit to find out if composition is
permitted.

Compositionality is an appealing paradigm to follow because it means we can
split complicated circuits into simpler parts; by repeatedly splitting up
circuits we eventually reach some indivisible atomic components.
If one defines the behaviour of these components and how they interact
with composition, it is possible to establish the behaviour of some
larger circuit \(f\) \emph{inductively} breaking it down into its constituent
parts.

\[
    \iltikzfig{strings/compositional/example-0}
    =
    \iltikzfig{strings/compositional/example-1}
    =
    \iltikzfig{strings/compositional/example-2}
\]

To prove properties about \(f\), we can prove properties
about \(g\) and \(k\) and verify if horizontal and vertical composition
\emph{preserves} these properties.

While it is possible to work with this surface-level notion of
compositionality, it is important to establish a mathematical
foundation to determine what it means to compose and the properties that
arise from it; for this, we turn to
\emph{category theory}~\cite{maclane1978categories}.

A \emph{category} is made up of \emph{objects} and \emph{morphisms} (`arrows')
between them.
Any two arrows \(\morph{f}{A}{B}\) and \(\morph{g}{B}{C}\) can be
\emph{composed} to  make a new morphism \(\morph{g \circ f}{A}{C}\), and every
object \(A\) has a unique \emph{identity} morphism \(\id[A]\).
Composition is \emph{associative} and \emph{unital}; that is to say, the
following equations hold:
\[
    (h \circ g) \circ f = h \circ (g \circ f)
    \qquad
    f \circ \id[A] = f
    \qquad
    \id[B] \circ f = f
\]
It turns out that this simple concept paves the way to an array of
theorems that can generalise many areas of computer science, mathematics, and
beyond.

It is straightforward to see how a compositional process with inputs of type
\(A\) and outputs of type \(B\) could be modelled as a morphism
\(\morph{f}{A}{B}\).
But to model more complex processes one needs to work with a class of categories
known as
\emph{freely generated symmetric monoidal categories}~\cite{maclane1963natural},
categories equipped with an additional notion of \emph{parallel} composition
\(\tensor\) along with a family of morphisms
\(\morph{\swap{A}{B}}{A\tensor B}{B \tensor A}\) known as \emph{symmetries} to
swap over inputs.
Using a set of primitive components as \emph{generators}, the two composition
operators can be used in combination with the identities and symmetries to build
up more complicated terms.
These terms can be written as \emph{term strings}, such as the following:
\[
    \id[1]
    \tensor
    (f\ \tensor\ g
    \seq
    \swap{1}{1}
    )
    \seq
    (h\ \tensor\ \id[1] \seq f)
    \tensor
    \id[1]
    \seq
    g
\]

Terms described in this way are quite unintuitive, as the two different types of
composition are compressed into a one-dimensional text string.
Fortunately, symmetric monoidal categories admit an intuitive graphical notation
known as \emph{string diagrams}, in which generators are drawn as boxes
connected by wires, with the identity depicted as an empty wire and the symmetry
as swapping over wires.
For example, the term described above can be depicted diagrammatically as
follows.
\[
    \iltikzfig{strings/example-smc}
\]

String diagrams do not add any more computational power to
standard one-dimensional reasoning, but they are
immensely beneficial because the categorical axioms of associativity and
unitality are `absorbed' by the notation: two morphisms are equal if and only if
their string diagrams are isomorphic~\cite{kelly1980coherence,kissinger2014abstract}.
This makes proofs far less bureaucratic, as one can focus on the non-trivial
steps without having to constantly rearrange the bracketing of a term.
String diagrams also make the work more approachable and easier to explain to
non-mathematicians; using the diagrammatic approach it is possible to give talks
about category theory without mentioning categories at all.
There have even been books written with this
philosophy~\cite{coecke2018picturing}.


\section{Compositionality and sequential circuits}

One might argue that composition is already widespread in sequential circuit
design, and indeed it is: circuits are constructed by connecting lots of very
common primitive components together to make something more complex.
But this is done informally, as the behaviour of a circuit is usually tested
by \emph{simulating} it and seeing what happens.
We can simulate the subcomponents, but what does this mean for their composite?
Without a guarantee of full compositionality, we have no reason to
believe that connecting two well-behaved circuits together will result in
another well-behaved circuit.

Progress towards full compositionality for sequential circuits has been hampered
by the presence of the dreaded \emph{non-delay-guarded feedback loop}; a cycle
that does not pass through any state registers.
Non-delay-guarded feedback can lead to undefined behaviour; for example, it is
not immediately obvious what the first input to the primitive gate below should
be.
\[
    \iltikzfig{circuits/instant-feedback/trand-no-value}
\]

Some approaches try to nullify this by considering only some `safe' subset of
circuits which will always be well-behaved~\cite{christensen2021wire}, by
introducing some sort of `type system' on wires so that components may only be
connected if they are guaranteed to have well-defined behaviour at the same
points in time~\cite{nigam2023modular}, or by only considering certain kinds of
composition~\cite{alekseyev2014compositional}.
While these are useful perspectives, they still shy away from true full
compositionality for sequential circuits.

Even though there are indeed times when non-delay-guarded feedback can lead to
unwanted behaviour, careful use can still result in useful circuits, so it
should not be excluded from our mathematical theory of sequential circuits.
For example, if we were to enforce that every loop in our circuits is
`delay-guarded', we cannot `yank out' an otherwise trivial loop of wires as
below, because that would implicitly delete a delay and alter the outputs of the
circuit over time.
\[
    \iltikzfig{circuits/examples/yanking-lhs}
    =
    \iltikzfig{circuits/examples/yanking-rhs}
    =
    \iltikzfig{circuits/examples/yanking-simple}
\]

Non-delay-guarded feedback can also be used in clever ways to create sequential
circuits that exhibit combinational behaviour.
The following is a classic example~\cite{malik1994analysis} in which the
feedback is just used to share resources; the circuit acts as \(f \seq g\) or
\(g \seq f\) depending on the control input \(\mathsf{c}\).
\[
    \iltikzfig{circuits/examples/cyclic-combinational/circuit}
\]
Such circuits, while not following conventional design methodology, are more
efficient in terms of circuit size and power consumption.
This once more illustrates how working in a setting where not all loops are
delay-guarded may be beneficial to us.

\section{Theories of digital circuits}

While this thesis details a fully compositional
\emph{categorical} theory of digital circuits, this is by no means the first
time sequential circuits have been given the mathematical treatment.
\emph{Mealy machines}~\cite{mealy1955method}, the \emph{de facto} structure for
specifying the behaviour of sequential circuits, are ancient and it is well
known how they should be composed~\cite{ginzburg2014algebraic}.
In more recent times Mealy machines have been given a categorical treatment as
certain kinds of \emph{coalgebra}~\cite{rutten2006algebraic,bonsangue2008coalgebraic}.
However, Mealy machines abstract away from the \emph{components} of the circuit;
we are keen to preserve the link between structure and behaviour.

While not explicitly categorical, the idea of representing circuits as
mathematical expressions built up from primitive components was studied in the
80s by Gordon, who worked on
\emph{denotational semantics for sequential machines}~\cite{gordon1980denotational}
and used this idea to present
\emph{a model of register transfer systems}~\cite{gordon1982model}.
Gordon subsequently noted that \emph{higher order logic} would make a good fit
for a hardware description language~\cite{gordon1985why}, and this has become
a ubiquitous concept in formal verification of hardware~\cite{gupta1992formal}.

The first steps towards a categorical theory of digital circuits took place at
the turn of the millennium, when Lafont presented an
\emph{algebraic theory of boolean circuits}~\cite{lafont2003algebraic}.
This work already bears a great resemblance to the framework presented in this
thesis; circuits
are presented as morphisms in a symmetric monoidal category freely generated
over a set of primitive logic gates.
However, Lafont's work only considered circuits for \emph{Boolean functions};
these circuits did not have any notion of delay or feedback.
\[
    \iltikzfig{circuits/examples/lafont}
\]
It was not until 2016 that \emph{sequential} circuits were given the
categorical treatment by Ghica and Jung~\cite{ghica2016categorical}, who were
later joined by Lopez when considering how to use this for a graph-rewriting
based operational semantics~\cite{ghica2017diagrammatic}.
\[
    \iltikzfig{circuits/examples/sr-latch/circuit}
\]
In this line of work, sequential circuits were modelled as morphisms in a
\emph{symmetric traced monoidal category}, a symmetric monoidal category
extended with a \emph{trace operator}.
In the context of sequential circuits, the trace operator models
\emph{feedback}.
\[
    \trace{}{
        \iltikzfig{strings/category/f-2-2}[colour=white,box=f]
    }
    =
    \iltikzfig{strings/traced/trace-rhs}[colour=white,box=f]
\]
This marks a departure from many other recent works on compositional processes
such as the work on string diagrammatic
\emph{signal flow theory}~\cite{bonchi2021survey} or analog
circuits~\cite{boisseau2022string}, which operate in a setting with a
\emph{Frobenius} structure equipped with a commutative monoid \((
\iltikzfig{strings/structure/monoid/merge},
\iltikzfig{strings/structure/monoid/init}
)\) and a cocommutative comonoid \((
\iltikzfig{strings/structure/comonoid/copy},
\iltikzfig{strings/structure/comonoid/discard}
)\).
The primary difference in such settings is that wires are implicitly
bidirectional and can be `bent' by using these primitive components.
\[
    \iltikzfig{strings/compact-closed/cup}
    \coloneqq
    \iltikzfig{strings/structure/frobenius/cup}
    \quad
    \iltikzfig{strings/compact-closed/cap}
    \coloneqq
    \iltikzfig{strings/structure/frobenius/cap}
\]
The Frobenius setting is appealing because a feedback loop can be
constructed by piecing together tiles rather than having to use an explicit
operation.
\[
    \iltikzfig{strings/traced/trace-from-product}
\]
So why not opt for such a route for sequential circuits?
One might think that the bidirectional nature of the wires already raises a
problem, as digital circuits have a much more rigorous notion of input-output
causality: they model \emph{functions} rather than \emph{relations}.
But even in a Frobenius setting it is possible to restrict to the circuits with
`left-to-right' flow, as illustrated in~\cite{bonchi2021survey}.

The actual problem arises from the construction of the trace from smaller
components; since circuits have a notion of \emph{copying}, this is
fundamentally incompatible with the Frobenius structure.
\[
    \iltikzfig{strings/traced/trace-from-product}
    =
    \iltikzfig{strings/traced/trace-from-product-1}
    =
    \iltikzfig{strings/traced/trace-from-product-2}
    =
    \iltikzfig{strings/traced/trace-from-product-bialg}
\]
For this reason, any feedback loop on circuits needs to be constructed as one
operation.

\section{Contributions}

This contributions of this thesis are split into two parts,
\emph{Semantics of Digital Circuits}, and
\emph{Graph Rewriting for Digital Circuits}.
These sections respectively correspond to two papers:
\emph{%
    A Fully Compositional Theory of Sequential Digital Circuits:
    Denotational, Operational and Algebraic Semantics%
}~\cite{ghica2024fully}, and \emph{%
    Rewriting Modulo Traced Monoidal Structure%
}~\cite{ghica2023rewriting}, which was published in
\emph{Formal Structures for Computation and Deduction (FSCD) 2023}.

\subsection{Semantics of Digital Circuits}

In previous work, semantics of digital circuits was defined in a confusing
manner, intermingling equations on circuits with other quotients.
In the first part of this thesis we set about fixing this: we first define the
categorical syntax of sequential digital circuits and follow this up with three
sound and complete semantic frameworks: denotational, operational, and
algebraic.
Each of these frameworks has their own benefits and intended uses; together they
form a comprehensive examination of semantics of digital circuits.
The framework is sufficiently general to encompass circuits constructed from
all manner of components ranging from the level of transistors to the level of
logic gates and beyond, but to provide some intuition we
include an extended case study into circuits constructed from
\emph{Belnap logic gates}~\cite{belnap1977useful}, an extension of traditional
Boolean logic containing the usual \(\andgate\), \(\orgate\) and \(\notgate\)
gates.
An overview of the categories involved can be seen in \cref{fig:circuits-map}.

\begin{figure}
    \centering
    \includestandalone{figures/circuits/map}
    \caption{Categories of digital circuits}
    \label{fig:circuits-map}
\end{figure}

\subsubsection{\cref{chap:syntax}: Syntax of sequential circuits}

Previously, the syntax and semantics of digital circuits were defined in a
haphazard way; categories of syntactic circuits were immediately quotiented by
some ad-hoc `natural laws' and `extensional equivalence'.
We take a more modular approach, in which we first define the syntactic
categories \(\ccircsigma\) of \emph{combinational} circuits and \(\scircsigma\)
of \emph{sequential} circuits.
These are categories in which we can construct circuit morphisms; the three
semantic theories that we will present next provide different ways of
\emph{quotienting} these categories in order to identify circuits with the same
behaviour under some interpretation.

\subsubsection{\cref{chap:denotational}: Denotational semantics}

While the previous circuits work discussed assigning semantics to circuits in
terms of streams, soundness and completeness of this model was not considered.
It was not even deemed important enough to appear in the conference version of
the paper, only being examined in detail in the arXiv
preprint~\cite{ghica2017diagrammatica}.
Here we present a category \(\streami\) of \emph{stream functions} with certain
properties, which serve as the denotational semantics for sequential circuits.
This denotational semantics is sound and complete in that every syntactic
circuit can be expressed as one of these stream functions, and every such stream
function can be mapped to a syntactic circuit which has the original stream
function as its behaviour.

Along the way, we also define a category \(\mealyi\)  of Mealy machines lifted
to work on lattices as a `bridge' between circuits and stream functions.
As well as being essential for showing the soundness and completeness of the
denotational semantics, having this category of Mealy machines is nice to have
in its own right, as it shows how existing circuit
methodologies~\cite{kohavi2009switching} are compatible with our rigorous
mathematic framework.

Circuits that map to the same stream function are called
\emph{denotationally equivalent}.
By quotienting \(\scircsigma\) by denotational equivalence we obtain a category
\(\scircsigmai\); this is the category against which we will compare our next
two semantic theories.

\subsubsection{\cref{chap:operational}: Operational semantics}

The original motivation for a categorical theory of circuits was to create an
\emph{operational semantics} for digital circuits, bringing techniques from
software to hardware.
While such a system was presented in~\cite{ghica2017diagrammatic}, this only
worked on \emph{closed} circuits with no \emph{non-delay-guarded feedback}.
One of the main contributions of this chapter is to lift this restriction using
a novel reduction rule for eliminating non-delay-guarded feedback inspired by
the Kleene fixpoint theorem.
Combined with a generalisation of the previous reduction procedure to
work on open circuits, this means that any circuit applied to some inputs can be
reduced in order to determine its outputs and next state.

As a result of this, we also present a new formal notion of
\emph{observational equivalence} on sequential circuits, and show that it is the
correct one using the well-known universal property that it is the largest
adequate congruence relation~\cite{gordon1998operational}.
Quotienting \(\scircsigma\) by observational equivalence gives us another
semantic category of circuits \(\scircsigmaobs\).
By establishing an isomorphism between \(\scircsigmai\) and \(\scircsigmae\)
we show that the operational semantics is also sound and complete: two circuits
have the same behaviour as stream functions if and only if they reduce to the
same outputs for all inputs.

\subsubsection{\cref{chap:algebraic}: Algebraic semantics}

The previous framework of digital circuits was presented as an
\emph{algebraic semantics}: the category of circuits was quotiented by certain
`natural laws', which were stated as axioms rather than being derived from any
mathematical model.
These equations were not actually enough to show the desired results, so
additional quotients of `extensional equivalence' were used to add in the
remaining equalities.

In this thesis our equational theory is guided by the stream semantics,
building up to an algebraic semantics for circuits without having to add any
arbitrary quotients.
We try to stick to standard equations on algebraic structures and small `local'
equations detailing the interactions on individual generators, but the nature of
digital circuits means that some larger circuits including \emph{context} are
necessary to include.
The main result is showing the equations suffice to bring any circuit to a
pseudo-normal form.

Quotienting \(\scircsigma\) by these equations gives us our last semantic
category \(\scircsigmae\).
Establishing an isomorphism between \(\scircsigmai\)
and \(\scircsigmaobs\) shows that the algebraic semantics is sound and complete:
two circuits have the same behaviour as stream functions if and only if they
can be translated into each other using the equations.

\subsubsection{\cref{chap:semantics-applications}: Potential applications}

We conclude the first part of the thesis by examining some potential
applications for the categorical framework of digital circuits.
In particular, we show how one could use the framework for
\emph{partial evaluation} of circuits, and how we can use (in)equational
reasoning to develop more efficient circuits.

\subsection{Graph Rewriting for Digital Circuits}

\begin{figure}
    \centering
    \includestandalone{figures/graphs/roadmap}
    \caption{Categories of terms and cospans of hypergraphs}
    \label{fig:hypergraphs-map}
\end{figure}

While this work marks the first time the semantics of sequential digital
circuits have been given a rigorous mathematical treatment, it is not really
feasible to apply the techniques to anything more than toy circuits by hand;
trying to manually apply the techniques to actual, practical, circuits would
quickly become impractical.
Instead it is desirable to have a computer deal with all the hard work
for us and reason \emph{automatically}.
To do this, we need to represent circuits \emph{combinatorially} as graphs.

Representing the categorical syntax of digital circuits in this way was
considered in~\cite{ghica2017diagrammatic} using
Kissinger's \emph{framed point graphs}~\cite{kissinger2012pictures}.
These had several drawbacks, such as the need to reason modulo
\emph{wire homeomorphism} and the fact that framed point graphs were not fully
adhesive.
In the second part of the thesis, we extend more recent work on
\emph{hypergraph string diagram rewriting}~\cite{bonchi2022string,bonchi2022stringa,bonchi2022stringb}
so we can apply it to sequential digital circuits.
An overview of the categories involved can be seen in
\cref{fig:hypergraphs-map}.

\subsubsection{\cref{chap:hypergraphs}: String diagrams as hypergraphs}

Previous work on hypergraph string diagram hypergraph rewriting showed how terms
in a freely generated symmetric monoidal category \(\smcsigma\) equipped with a
\emph{special commutative Frobenius structure} \(\frob\) correspond to morphisms
in a category of \emph{cospans of hypergraphs} \(\cspdhyp\), and terms without a
Frobenius structure correspond to morphisms in a category of
cospans of \emph{monogamous acyclic} \(\macspdhyp\).

We extend this work to terms in a freely generated symmetric traced monoidal
category \(\stmcsigma\); since these terms occupy the space in between regular
symmetric monoidal terms and those with a Frobenius structure, the interpretation as
cospans accordinly sits between \(\macspdhyp\) and \(\cspdhyp\) in the form of
the category of \emph{partial monogamous} cospans of hypergraphs \(\pmcspdhyp\).

We furthermore extend this to the case where the traced terms are additionally
equipped with a cocommutative comonoid structure \(\ccomon\), leading to a
category of \emph{partial left-monogamous} cospans of hypergraphs
\(\plmcspdhyp\).

\subsubsection{\cref{chap:rewriting}: Graph rewriting}

Reasoning on terms interpreted as cospans of hypergraphs is performed using
\emph{double pushout (DPO) graph rewriting}.
The main computational step during this procedure is identifying a valid
\emph{pushout complement}: the context of the rewrite step.
Bonchi et al showed that or Frobenius terms, any pushout complement corresponds
to a term rewrite~\cite{bonchi2022string}, and for symmetric monoidal terms
exactly one pushout complement corresponds to a term
rewrite~\cite{bonchi2022stringa}: the \emph{boundary complement}.

For the traced and traced comonoid case some pushout complements are valid and
some are not.
We characterise those that are as \emph{traced boundary complements} in the case
of the former and \emph{traced left-boundary complements} in the case of the
latter.

\subsubsection{\cref{chap:graphs-applications}: Applications of graph rewriting}

Interpreting circuits as hypergraphs introduces the opportunity to evaluate them
\emph{automatically} using graph rewriting.
As a first case study, we show how graph rewriting modulo traced comonoid
structure can aid reasoning in settings with a \emph{Cartesian} structure, of
which the semantic categories of digital circuits are an example.

Subsequently, we illustrate how graph rewriting can be used as a combinatorial
implemnetation of the operational semantics for digital circuits.
This culminates in the presentation of a graph-rewriting-based hardware
description language based on the work throughout the thesis, with which one can
design and (partially) evaluate circuits in a step-by-step manner.